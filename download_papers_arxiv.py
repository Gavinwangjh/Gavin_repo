# download_papers_arxiv.py
import os
import re
import arxiv

OUT_DIR = "data/pdfs"
os.makedirs(OUT_DIR, exist_ok=True)

def safe_filename(name: str) -> str:
    """æ¸…ç†éæ³•è·¯å¾„å­—ç¬¦"""
    name = re.sub(r'[\\/*?:"<>|]', "_", name)
    name = name.replace("\n", " ").strip()
    return name[:120]

def download_papers(query="cat:cs.CL", max_results=30):
    print(f"\nğŸ” æ­£åœ¨æœç´¢: {query}")
    search = arxiv.Search(
        query=query,
        max_results=max_results,
        sort_by=arxiv.SortCriterion.SubmittedDate,
    )

    for paper in search.results():
        # ğŸŸ¢ arXiv åŸç‰ˆ PDF URL
        pdf_url = paper.pdf_url.strip()

        filename = safe_filename(paper.title) + ".pdf"
        filepath = os.path.join(OUT_DIR, filename)

        if os.path.exists(filepath):
            print(f"â© å·²å­˜åœ¨: {filename}")
            continue

        print(f"â¬‡ æ­£åœ¨ä¸‹è½½: {paper.title}")
        try:
            paper.download_pdf(filename=filepath)  # å®˜æ–¹ PDF
        except Exception as e:
            print("âš  ä¸‹è½½å¤±è´¥:", e)
            continue

    print("\nğŸ‰ ä¸‹è½½å®Œæˆï¼\n")

if __name__ == "__main__":
    download_papers(query="cat:cs.CL", max_results=50)      # NLP
    download_papers(query="cat:cs.LG", max_results=50)      # ML
    download_papers(query="retrieval augmented generation", max_results=30)  # RAG ä¸“é¢˜
    download_papers(query="transformer", max_results=20)
